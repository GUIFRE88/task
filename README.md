
---
<h1 align="center">
  üöÄ Task and Scraping üöÄ
</h1>
<br>



Esse projeto foi desenvolvido com as seguintes tecnologias:

- [Ruby](https://www.ruby-lang.org/pt/)
- [React](https://reactjs.org)
- [Chakra-ui](https://v2.chakra-ui.com/)
- [MySql](https://www.mysql.com/)
- [Docker](https://www.docker.com/)

<div style="display: inline_block"><br>
  <img align="center" alt="Gui-Ruby" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/ruby/ruby-original.svg">
  <img align="center" alt="Gui-React" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/react/react-original.svg">
  <img align="center" alt="MySql" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original.svg">
  <img align="center" alt="Docker" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original.svg">
</div>

-----

# üíª Projeto

Este projeto √© uma aplica√ß√£o Ruby on Rails desenvolvida para realizar scraping do site WebMorts. O objetivo √© coletar a marca e modelo do ve√≠culo.

#  üíª Passos para montar ambiente local
* Entrar na pasta do Projeto, e rodar `docker compose build`.
* Ap√≥s entrar no bash de cada microservi√ßo
    * Bash do servi√ßo de autentica√ß√£o: `docker exec -it auth_service bash`
    * Bash do servi√ßo de notifica√ß√£o: `docker exec -it notification_service bash`
    * Bash do servi√ßo de scrapping: `docker exec -it scraping_service bash`
    * Bash do servi√ßo de tarefas: `docker exec -it task_management bash`
    * Rodar o comando `rails db:migrate` em cada umm deles para criar as tabelas. 
* Entrar na pasta <b>front-end</b> e rodar `npm install` para baixar os pacotes.
* Ap√≥s rodar o comando `npm start` para iniciar front-end.


### Busca dos valores:
O scraping dos valores √© feito atrav√©s da gem <b>Nokogiri</b>, por√©m como o site WebMotors possuia uma valida√ß√£o de ReCapatcha, foi necess√°rio fazer a busca dentro do Sidekiq, enfilerando os registros e fazendo uma busca em cada 5 minutos, mesmo que seja pedido para fazer 10 buscas ao mesmo tempo, foi necess√°rio enfilerar essas requisi√ß√µes, para que n√£o ocorra o problema de bloquio pelo ReCapatcha, portanto cada busca ser√° feito dentro de 5 minutos.


### Notifica√ß√£o no Front-end do termino do Scraping:

Quando for finalizado o Scraping do modelo e marca do ve√≠culo no site WebMotors, ser√° enviado uma notifica√ß√£o para o front-end feito em React atrav√©s de um <b>WebSocket</b>, essa conex√£o de WebSocket √© feita atrav√©s do `user_id`, portanto s√≥ mostrar√° a notifica√ß√£o para o user que fez a cria√ß√£o da tarefa.

### Componentes do front-end:

Acabei optando por utilizar a biblioteca de componentes <b>Chakra-ui</b>, pois ela oferece componentes e estiliza√ß√µes de uma maneira simples, temos outras como Tailwind, por√©m tenho mais viv√™ncia com Chakra-ui, acabei escolhendo por esse frame.

Obs. O servidor do React dever√° rodar na porta localhost:3004, pois as demais portas como 3000, 3001, 3002 e 3003 s√£o ocupadas pelo microsservi√ßos. 

### Bloqueio de rotas sem login:

Dentro do application_controller de cada microservi√ßo foi implementado uma verifica√ß√£o, atrav√©s do Barear Token, caso o mesmo n√£o seja enviado pela requisi√ß√£o e seja um token v√°lido, ser√° retornado uma mensagem de sem autentica√ß√£o e retornar√° status 401. 

#  üíª Tela login
<br>
Na tela de login, possuimos apenas o campo de Email e Password, decidi fazer uma tela simples, por√©m objetiva. 
<br>

![alt text](https://github.com/GUIFRE88/task/blob/main/images/Login.png)

#  üíª Tela de cadastro
<br>
√â possivel criar um usu√°rio, informando Email e Senha, ele poder√° ser utilizado posteriormente para logar na aplica√ß√£o. 
<br>

![alt text](https://github.com/GUIFRE88/task/blob/main/images/Register.png)

#  üíª Tala de Tarefas
<br>
Nessa tela possu√≠mos a listagem de todas as tarefas. Temos o bot√£o de incluir uma tarefa, deslogar do sistema, atualizar uma tarefa, excluir uma tarefa e tamb√©m o bot√£o para verificar os scrapings j√° realizados.
<br>

![alt text](https://github.com/GUIFRE88/task/blob/main/images/ListaDeTarefas.png)


#  üíª Incluir uma Tarefa
<br>
√â poss√≠vel incluir uma tarefa, informando a URL e o campo de Tipo, caso seja o tipo scraping, ser√° feito o scraping do site informado no campo url. 
<br>

![alt text](https://github.com/GUIFRE88/task/blob/main/images/IncludeTask.png)



#  üíª Editar uma Tarefa

<br>

√â poss√≠vel editar a URL ou Tipo da tarefa. 

<br>

![alt text](https://github.com/GUIFRE88/task/blob/main/images/EditTask.png)



#  üíª Notifica√ß√£o de finaliza√ß√£o do Scraping

<br>
Ap√≥s processar no Sidekiq o Scraping do site, ser√° enviado uma notifica√ß√£o tipo Toas para o front-end React, atrav√©s de um WebSocket com o objetivo de avisar o usu√°rio que o pedido de Scraping, finalizou, ap√≥s isso ser√° poss√≠vel ver as informa√ß√µes buscadas no bot√£o `See scraping`.
<br>

![alt text](https://github.com/GUIFRE88/task/blob/main/images/NoticateScraping.png)

#  üíª Ver listagem de Scraping realizados

<br>

Temos o bot√£o `See scraping`, onde ser√° poss√≠vel verificar todos os scrapings feitos naquela atividade, como temos a possibilidade de alterar a url da tarefa, eu optei por ter o hist√≥rico de todos os scrapings j√° feitos na tarefa. 

<br>

![alt text](https://github.com/GUIFRE88/task/blob/main/images/SeeScraping.png)


#  üíª Rotas da Api

## Auth Service

### singup

![alt text](https://github.com/GUIFRE88/task/blob/main/images/auth/auth-signup.png)

### login

![alt text](https://github.com/GUIFRE88/task/blob/main/images/auth/auth-login.png)

### validate

![alt text](https://github.com/GUIFRE88/task/blob/main/images/auth/auth-token.png)


## Task Management

### create

![alt text](https://github.com/GUIFRE88/task/blob/main/images/task/task-create.png)

### index

![alt text](https://github.com/GUIFRE88/task/blob/main/images/task/task-index.png)

### show

![alt text](https://github.com/GUIFRE88/task/blob/main/images/task/task-show.png)

### update

![alt text](https://github.com/GUIFRE88/task/blob/main/images/task/task-update.png)

### delete

![alt text](https://github.com/GUIFRE88/task/blob/main/images/task/task-delete.png)


## Scraping Service

### start_scraping

![alt text](https://github.com/GUIFRE88/task/blob/main/images/scraping/scraping-start.png)

### index

![alt text](https://github.com/GUIFRE88/task/blob/main/images/scraping/scraping-index.png)


## Notification Service

### create

![alt text](https://github.com/GUIFRE88/task/blob/main/images/notification/notification-create.png)

### show

![alt text](https://github.com/GUIFRE88/task/blob/main/images/notification/notification-show.png)



---

# üíª Rspec
Implementado testes com Rspec em cada projeto individualmente, por favor verifique a pasta /spec de cada projeto.



#  üíª Melhorias no projeto

Todo projeto oferece desafios e melhorias, creio que as melhorias seriam:

 * Gostaria de ter implementado algum servi√ßo para quebra do ReCaptcha, pois o site do WebMotors estava bloquando quando eram feitas muitas requisi√ß√µes, uma forma de burlar isso foi atrav√©s da utiliza√ß√£o do Sidekiq, por√©m temos alguns servi√ßos que podem fazer o preenchimento do ReCaptacha, mas os melhores que eu encontrei eram pagos.
 * A parte do front-end poderia apresentar uma pagina√ß√£o, talvez utilizando a gem <b>will_paginate</b>, decidi n√£o fazer nesse momento, por√©m gostaria de implementar isso no sistema futuramente, compreendo a importancia disso pensando em uma grande quantidade de registros.


# üíª Contribui√ß√£o
Sinta-se √† vontade para contribuir com melhorias ou corre√ß√µes! Para isso, fa√ßa um fork do reposit√≥rio, crie uma branch com suas altera√ß√µes e envie um pull request.

# üíª Licen√ßa
Este projeto est√° licenciado sob a MIT License.


----
